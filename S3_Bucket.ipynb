{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d333254",
   "metadata": {},
   "source": [
    "## S3 Bucket Operations\n",
    "\n",
    "1. Creating client using resource\n",
    "2. Upload Files to S3 Bucket\n",
    "3. Download Files from S3\n",
    "4. Loading CSV file from S3 bucket using Pandas\n",
    "5. Upload bulk of files on S3 bucket\n",
    "6. Download bulk of files from bucket\n",
    "7. Getting names of all files from the bucket\n",
    "8. Getting names of bucket from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61a0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "from botocore.client import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba980d2",
   "metadata": {},
   "source": [
    "### 1. Creating client using resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45c938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 bucket on AWS, get aws_access_key_id and aws_secret_access_key credentials from IAM AWS\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-east-2',\n",
    "    aws_access_key_id='<aws_access_key_id>',\n",
    "    aws_secret_access_key='<aws_secret_access_key>'\n",
    ")\n",
    "\n",
    "my_bucket = s3.Bucket('predictionwaferfiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e73a2",
   "metadata": {},
   "source": [
    "### 2. Upload Files to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4313a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to bucket specifying the bucket's name created on AWS S3\n",
    "\n",
    "my_bucket = s3.Bucket('predictionwaferfiles')\n",
    "\n",
    "# Key name can be any name given to file to save it on S3 bucket\n",
    "# Filename is the file to upload (file_path needs to specified if it's in a different folder)\n",
    "\n",
    "my_bucket.upload_file(Filename='Input.csv', Key='Input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f67f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input.csv\n"
     ]
    }
   ],
   "source": [
    "# Check if file has been uploaded\n",
    "\n",
    "for files in my_bucket.objects.all():\n",
    "    print(files.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631ecc2",
   "metadata": {},
   "source": [
    "### 3. Download Files from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45365808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to bucket\n",
    "my_bucket = s3.Bucket('predictionwaferfiles')\n",
    "\n",
    "# Creating a directory to save the file from bucket\n",
    "os.makedirs(\"S3\")\n",
    "\n",
    "# Key is the name of the file in the bucket\n",
    "# Filename is the name that you want your file to be saved as, also specifying the path where the file has to be saved\n",
    "\n",
    "my_bucket.download_file(Filename='S3/InputDownload.csv', Key='Input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce7e0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InputDownload.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if file has been downloaded\n",
    "\n",
    "os.listdir(\"S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883d56f",
   "metadata": {},
   "source": [
    "### 4. Loading CSV file from S3 bucket using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d13288cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>620dfa7bd16ece6bc2785777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dikshya Pradhan</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>620dfa7bd16ece6bc2785778</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>620dfa7bd16ece6bc2785779</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sam Claflin</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>620dfa7bd16ece6bc278577a</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chris Evans</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>620dfa7bd16ece6bc278577b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       _id  PassengerId  Survived  Pclass  \\\n",
       "0           0  620dfa7bd16ece6bc2785777            1         0       3   \n",
       "1           1  620dfa7bd16ece6bc2785778            2         1       1   \n",
       "2           2  620dfa7bd16ece6bc2785779            3         1       1   \n",
       "3           3  620dfa7bd16ece6bc278577a            4         1       1   \n",
       "4           4  620dfa7bd16ece6bc278577b            1         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                                    Dikshya Pradhan    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                                        Sam Claflin  female   38      1   \n",
       "3                                        Chris Evans  female   38      1   \n",
       "4                             Heikkinen, Miss. Laina    male   22      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  \n",
       "2      0   PC 17599  71.2833   C85        C  \n",
       "3      0   PC 17599  71.2833   C85        C  \n",
       "4      0  A/5 21171   7.2500   NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to bucket\n",
    "my_bucket = s3.Bucket('predictionwaferfiles')\n",
    "\n",
    "\n",
    "# Specify the name of file to be read and create an object\n",
    "obj = my_bucket.Object('Input.csv').get()\n",
    "\n",
    "\n",
    "# Read the csv file specifying the file name as obj['Body']\n",
    "df = pd.read_csv(obj['Body'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db9ef9",
   "metadata": {},
   "source": [
    "### 5. Upload bulk of files on S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e82e09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "from botocore.client import ClientError\n",
    "\n",
    "class UploadRawDataToCloud:\n",
    "    \"\"\"\n",
    "    This class shall be used for uploading all the data to AWS cloud from the local machine.\n",
    "\n",
    "    Written By: Dikshya Pradhan\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def trainingbatchfilestocloud(self):\n",
    "        try:\n",
    "            s3 = boto3.resource(\n",
    "            service_name='s3',\n",
    "            region_name='us-east-2',\n",
    "            aws_access_key_id='<aws_access_key_id>', # get the access_key_id from IAM AWS\n",
    "            aws_secret_access_key='<aws_secret_access_key>' # get the secret_access_key from IAM AWS\n",
    "            ) \n",
    "            \n",
    "            \n",
    "            # Specify the name of bucket \n",
    "            bucket=s3.Bucket('predictionwaferfiles')\n",
    "\n",
    "\n",
    "            data_path = os.path.join(os.getcwd(), 'Good_Raw/') # Specify the name of folder where files are stored\n",
    "            \n",
    "            # Listing the name of the files in the directory\n",
    "            files = os.listdir(data_path)\n",
    "\n",
    "            for file in files:\n",
    "                bucket.upload_file(Filename=data_path + file, Key=file)\n",
    "                \n",
    "        except ClientError as e:\n",
    "            return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d187aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wafer_16012020_051629.csv',\n",
       " 'wafer_21012020_080913.csv',\n",
       " 'wafer_20022020_090716.csv',\n",
       " 'wafer_13012020_090817.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if files are present in the local directory\n",
    "\n",
    "os.listdir('Good_Raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8899dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating object of class to push the above csv files to s3 Bucket\n",
    "\n",
    "push = UploadRawDataToCloud()\n",
    "\n",
    "\n",
    "# This method will push data to s3 bucket\n",
    "\n",
    "push.trainingbatchfilestocloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fae20097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input.csv\n",
      "wafer_13012020_090817.csv\n",
      "wafer_16012020_051629.csv\n",
      "wafer_20022020_090716.csv\n",
      "wafer_21012020_080913.csv\n"
     ]
    }
   ],
   "source": [
    "# Checking if files have been uploaded\n",
    "\n",
    "bucket=s3.Bucket('predictionwaferfiles')\n",
    "\n",
    "\n",
    "for files in bucket.objects.all():\n",
    "    print(files.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f6275f",
   "metadata": {},
   "source": [
    "### 6. Download bulk of files from bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3685c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directory to store files\n",
    "\n",
    "os.makedirs('DOWNLOADS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c5e7a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dikshyakasaju/Desktop/CODE FOR WAFER/DOWNLOADS/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a path to store the files from S3 bucket to local\n",
    "path=os.path.join(os.getcwd(), 'DOWNLOADS/')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc34e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket=s3.Bucket('predictionwaferfiles')\n",
    "\n",
    "\n",
    "for files in my_bucket.objects.all():\n",
    "    my_bucket.download_file(Key=files.key, Filename=path+files.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b8d5341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wafer_16012020_051629.csv',\n",
       " 'Input.csv',\n",
       " 'wafer_21012020_080913.csv',\n",
       " 'wafer_20022020_090716.csv',\n",
       " 'wafer_13012020_090817.csv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if files have been downloaded to the local directory\n",
    "\n",
    "os.listdir('DOWNLOADS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e58a5a",
   "metadata": {},
   "source": [
    "### 7. Getting names of all files from the bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75825ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='predictionwaferfiles', key='Input.csv')\n",
      "s3.ObjectSummary(bucket_name='predictionwaferfiles', key='wafer_13012020_090817.csv')\n",
      "s3.ObjectSummary(bucket_name='predictionwaferfiles', key='wafer_16012020_051629.csv')\n",
      "s3.ObjectSummary(bucket_name='predictionwaferfiles', key='wafer_20022020_090716.csv')\n",
      "s3.ObjectSummary(bucket_name='predictionwaferfiles', key='wafer_21012020_080913.csv')\n"
     ]
    }
   ],
   "source": [
    "for files in my_bucket.objects.all():\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60562d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input.csv\n",
      "wafer_13012020_090817.csv\n",
      "wafer_16012020_051629.csv\n",
      "wafer_20022020_090716.csv\n",
      "wafer_21012020_080913.csv\n"
     ]
    }
   ],
   "source": [
    "# Use key for getting only the names of files\n",
    "\n",
    "for files in my_bucket.objects.all():\n",
    "    print(files.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84af23fe",
   "metadata": {},
   "source": [
    "### 8. Getting names of bucket from AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "becff090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.Bucket(name='predictionwaferfiles')\n",
      "s3.Bucket(name='trainingwaferfiles')\n"
     ]
    }
   ],
   "source": [
    "for bucket in s3.buckets.all():\n",
    "    print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b77a27ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictionwaferfiles\n",
      "trainingwaferfiles\n"
     ]
    }
   ],
   "source": [
    "# Use name for getting only the names of buckets\n",
    "\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59391622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
